% CHAPTER 4 LESSON 1
\clearpage
\section{Spectrogram (narrow-band vs. wide-band)}
\label{Spectrogram (narrow-band vs. wide-band)}

 So what we now would like to do is apply the concept of the DFT and the fourier transform to speech signals and for that we first have to analyze the speech signal and then typically, some modification is done and then we must synthesize it again.
 
 The one tool that we use most frequently in audio processing to analyzse the spectral content is the short time fourier snalysis so what is the idea behind it?  Well its speech signals, like what I am saying right now is time varying, so an A is very different from  a ssss so we can't just take one speech utterance and compute the DFT of it and work with it because it is very different and you want to also see how the frequency content changes over time. FOr that we just have to split the signal into short segments and analyze each of them more or less independently of each other. So we can see how this spectral content changes over time. And we do this by means of the STFT. and basically all of the considerations that we did before still hold for the STFT and there are a set of parameters that you can choose for the STFT computation and they alwys depend upon what we want to use it. 
 
 So here is one example a chirp. A decreasing frequency and the na splash at the end. So these two signals are very different over time. If we were to compute the DFT of each part, they would look astonishinly the same.  Becasue here there is energy in high frequency decreasing in time.  If we were to take the mean over the time, the result would be similar to the splash.  So if we were to see the DFT of each part it would be hard to see what the underlying time domain signal would look like.  Therefore we do this analyis wher we can also see how it changes over time.  In this visulalization we can see how the chirp is time varying whereas the splash is broadband over time and is very different. 
 
 SO this is how we comput the STFT. Lets first see the analyis part of it. We use the sliding window transform.  We have a long speech signal and instead of taking one DFT of it we would rather take pieces. And for each segment, we apply the DFT.  But we learned some tricks before we apply the DFT.  We first apply an analysis window.  We could just cut it out and that would apply to having just a rectangular window or we could apply a Hann window for example to improve the spectral content or to reduce the spectral leakage.
 
 This can mathematically be stated this way, where the w is the analysis window of length N. l is the fram index and basically what you do is you have the window here and you multiply it with a shifted version of the original signal to get the current signal segment xl.  And there are some values here.  There is a window length N, a local time index starting a 0 and going to N-1, and there is a n overlap of these signals which in the way I drawed it there its about 50\%.  So each of these  time domain signal segemtns that are weighted with a window for them, the DFT is computed in that way.
 
   This is the typical formulation of the DFT. And its complex valued.  And these are the so called STFT coeffcient wher k is the frequency index and l is the frame index.  So for every frame we have some frequency bands.
   
   And here is one example of it.  Here is the chirp signal with the frequency increasing. A single tone sinusoid with increasing frequency and these two bell shaped curves represetn the analysis windows.  And then we apply the window and compute the DFT and that is what we get. This is however a diffuclt way of visualizing the result, so we use a spectrogram
 
 So there we have a two dimensional representation where we have on the xaxis, the time or the segemnt index and on the yaxis theres a frequencyand the actually amplitude of the magnitude is coded in color. So only the amplitude is considered, most of the times, the phase is not considered. So we limit ourselves to magnitude.
 
SO that is one spectrogram, but we learned that we have a lot of parameters to play around with, so its a choice of the window, the length of the window, also the overlap and we'll change some parameters. SO right now we have 16khz sampling frequency that has a bandwidth of 8khz and now lets change the size of the window from 512 to 32. What would you expect to change in the spectrogram.  Instead of using a rather long window, we use a rather short one SO you use a short window, you only use short segements, and you update them quite often so you have a high temppral resolution. However we learned that the resolution is 2pi over N. So we decrease N and the resolution in the frequency domain reduces. So we can either have high temporal resolution for short windows or have a bad resolution in the frequency domain or the other way around.  Have a long window, a high end, meaning a good resolution in the frequency domain, but we can't tract changes in the time domain signal that fast anymore. SO lets see what happens when we use such a short window.  It looks like this, you can see that where we were capable of resolving the harmonics, we are not capable of that anymore but you can see changes in energy very decently and you can even see like here you see these horizontal lines are not constant but now there is little energy, lot of energy, little energy that really depends how this fram lies relative to the frequency. What part of the sinusoid it is cutting out.  Although for this time here, the energy is rather constant, you have the long one, if you only use the short windows its high and then low again, high and then low again. Thats what you see here in the horinzontal lines.

So lets do the opposite, lets go for very long windows, lets say 2048.  Now we can see that its temporally smeared, but the spectral resoultion is quite high. You can even read it here.  So now lets see what zero padding does.  We leave the window length at 64, but change the STFT to 1024.  This is basically zero padding of 960.  We increase the N, meaning we increase the delta omega, but we learned that this will not increase the spectral resoulton.  Because we are just adding zeros, we should still not be able to resolve the harmonic components. Basically its just more less rough, more smooth picture, So a bit like interpolation in between but its not adding any new information to it. So now lets not do zero padding, but use a window length of 1024, now you can see that we are indeed capable of resolving the harmonic components. Then maybe one other example that we could have a look at, lets change the window function that we use so, its the Hamming window, lets take the Hann window.  SO you can see that there are minor changes in it because they basically look very much alike.  And now lets take the rectangular window and you can see that it looks like this . We can see the spectral leakage, everything is a bit blurred do to the spectral leakage. We change the window and we can see that we are back to normal again.

The resolution problem is limiting. YOu jkust have tolive with it.  and  you always have to find the best trade off for your application so if you want to like, if you have a fastly changing signals like a plosive that is very short then maybe it would be nice to use short windows, but like for an aaaaa that is very stationary, you can use longer windows and everything is alirigth.  It is always depending on the application.  Typical choices of window length are 20-30 ms.  Becasue you can assume most speech sounds to be rather stationary for segment length of upto 30ms that a rulle of thumb.  

SO here is an example for a wideband spectrogram, that is a spectrogram using short segements having a not so good frequency resolution.  And here is just the setup so for this picture here we used a window length of 5ms and window shift of 2.5ms which is an overlap of 50\% and we could, what I also showed in the program, is that we could also increase the FFT length, we add zeros at the end of the signal but we dont get any additional information but it looks nicer. These windows could rather well represent plosive sounds however the spectral resoultion is not good enough to resolve the harmonic structure of voiced speech.  Okay and here is the opposite of it.  A narrowband spectrogram. where we use longer segements. 32ms.  Window shift is also 50\% but you could also reduce it a bit more if you wanted. It decreases the computational load and gives a bit nicer piuctures.  It has rather long windows so it is not so good at tracking fast changing signals, but its good for rather stationary signals where you can allow rather long windows.  So here is a pictrure showing both spectrograms at the same time so they are the same signals.  Here is the narrowband, so good frequency resolution, and the wideband spectrogram where you can see what we already discussed. 


Slice Computation

Thats basically one conclusion slide. Thats for a typical setup, lets say 32ms, thats a rather good compromise its rather on the long side., but its still okay.  And we use frame shifts that correspond between 50 and 75 percent, sometimes even more and we use overlapping frames. and why that is I will be explaining in a few slides. And what we can also do is preemphasis.  Acoustic sounds in nature always obey a 6dB attenunation per octave, so towards higher frequencies, there is always an attenuation and that is is not a proble, but for visualization, this can be not to good. So therefore we can apply a highpass filter first wchich boostst the higher frequencies so that we get a bit nicer picture.  So this is only for visualization.  Normally this is not done for the modification, the actual processing. SO here there is no preemphasis on it, and now lets add some emphasis to the higher frequencies. Lets say 0.99. So now we can see that the higher frequencies are a bit more pronounced as before. 
So after splitting the signal into segement and maybe preemphasizing the signal, then the window is pllied to improve the spectral behavior and then we are basically done with the spectral analysis.
   